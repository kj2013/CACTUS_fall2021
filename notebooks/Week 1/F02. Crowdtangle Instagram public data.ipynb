{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib3\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "### https://github.com/CrowdTangle/API/wiki/Posts\n",
    "### https://help.crowdtangle.com/en/articles/1189612-crowdtangle-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "token = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key: Made a list of keywords for which I need the reddit posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#key=[\"covid\", \"coronavirus\",\"covid19\",\"covid-19\",\"hospital\",\"mask\",\"death\",\"infection\",\"quarantine\",\"virus\",\"symptom\",\"flu\",\"smell\",\"cough\",\"fever\",\"circuitbreaker\",\"wuhan virus\",\"chinese virus\"]\n",
    "key=[\"%23stayathome\", \"%23sgunited\",\"%23circuitbreakersg\",\"%23stayhomesg\",\"%23sgcircuitbreaker\",\"%23circuitbreaker\",\"%23sgunited\", \"%23stayhomeforsg\", \"%23movementcontrolorder\", \"%23safedistancing\",\"%23igsingapore\",\"%23sgtogether\",\"%23socialdistancing\",\"%23lockdown\"]\n",
    "userkey=[\"302218\",\"710418\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(1,len(userkey)):\n",
    "    print(i, userkey[i])\n",
    "#    for keywords: nexturl = 'https://api.crowdtangle.com/posts?token='+token+'&sortBy=total_interactions&endDate=2020-04-18T00:00:00&startDate=2020-01-01T00:00:00&searchTerm='+key[i]+'&count=100'\n",
    "# for posts by users:\n",
    "    nexturl = 'https://api.crowdtangle.com/posts/search?token='+token+'&inAccountIds='+ userkey[i]+'&sortBy=total_interactions&startDate=2020-02-01T00:00:00&endDate=2020-06-02T00:00:00&searchTerm=i&count=100'\n",
    "    while(nexturl.strip()):\n",
    "        time.sleep(20)\n",
    "        print(nexturl)\n",
    "        response = requests.get(nexturl)    \n",
    "        dict = response.json()\n",
    "        \n",
    "        if 'result' in dict.keys():\n",
    "            df = pd.DataFrame(dict['result']['posts'])\n",
    "            df[\"Label\"]='all'\n",
    "            dataset = pd.concat([dataset, df], ignore_index=True)\n",
    "            if 'nextPage' in dict['result']['pagination'].keys():\n",
    "                nexturl = dict['result']['pagination']['nextPage']\n",
    "            else:\n",
    "                nexturl=''\n",
    "        else:\n",
    "            print(dict)\n",
    "            nexturl=''\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of posts fetched\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 18)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count of number of posts for each keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "all    14\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.Label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('sing_allaccounts_jun18.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now create a list of ids of all the posts fetched. This will be used to get the comments of the posts fetched above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = list(dataset['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10880"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now traverse through the \"ids\" list to fetch the comment data one by one.\n",
    "#### In this case also, all the commented data is for each post is appended together to form a single comment CSV file i.e. \"dataset2\"\n",
    "Code below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,10880):\n",
    "    print(i)\n",
    "    url = 'http://api.pushshift.io/reddit/comment/search/?link_id='+str(ids[i])+'&size=50&sort_type=created_utc&sort=asc&filter=author,body,created_utc,score,subreddit,no_follow&score=>-100'\n",
    "    response = requests.get(url)    \n",
    "    dict = response.json()\n",
    "    df = pd.DataFrame(dict['data'])\n",
    "    df[\"id\"]=str(ids[i])\n",
    "    dataset2 = pd.concat([dataset2, df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving comment data as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2.to_csv('comment_dataset.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
